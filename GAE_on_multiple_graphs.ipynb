{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unitary p_np values:  1567\n",
      "Total number of zero p_np values:  483\n",
      "Total number of p_np values:  2050\n",
      "Percentage of unitary p_np values:  76.44 %\n",
      "Percentage of zero p_np values:  23.56 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This is graph autoencoder.\n",
    "The autoencoder is trained taking as input many graphs.\n",
    "The learned task of the autoencoder is to reconstruct a given molecule. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the data\n",
    "drug_data=pd.read_csv(\"BBBP.csv\")\n",
    "\n",
    "#sum all values equal to 1 in p_np column of drug_data\n",
    "total_unitary_pnp = sum(drug_data.p_np==1)\n",
    "print (\"Total number of unitary p_np values: \", total_unitary_pnp)\n",
    "\n",
    "#sum all values equal to 0 in p_np column of drug_data\n",
    "total_zero_pnp = sum(drug_data.p_np==0)\n",
    "print (\"Total number of zero p_np values: \", total_zero_pnp)\n",
    "\n",
    "# Print the total number of p_np values\n",
    "print (\"Total number of p_np values: \", len(drug_data.p_np))\n",
    "\n",
    "# Calculate the percentage of unitary p_np values\n",
    "print (\"Percentage of unitary p_np values: \", round(total_unitary_pnp*100/len(drug_data.p_np),2), \"%\")\n",
    "\n",
    "#calculate the percentage of zero p_np values\n",
    "print (\"Percentage of zero p_np values: \", round (total_zero_pnp*100/len(drug_data.p_np),2), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rdkit.Chem.rdchem.Mol'>\n",
      "0                      [Cl].CC(C)NCC(O)COc1cccc2ccccc12\n",
      "1              C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl\n",
      "2     c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...\n",
      "3                      C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C\n",
      "4     Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...\n",
      "5     CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(...\n",
      "6     CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@...\n",
      "7                   Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14\n",
      "8     COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@...\n",
      "9                          NC(N)=NC(=O)c1nc(Cl)c(N)nc1N\n",
      "10      OCC(C)(O)c1onc(c2ncn3c2CN(C)C(c4c3cccc4Cl)=O)n1\n",
      "11        CC1=CN([C@H]2C[C@H](F)[C@@H](CO)O2)C(=O)NC1=O\n",
      "12                                              C(Cl)Cl\n",
      "13    C1N(C(CC2CCCCC12)C(NC(C)(C)C)=O)CC(C(Cc1ccccc1...\n",
      "14               CCC(=O)C(CC(C)N(C)C)(c1ccccc1)c2ccccc2\n",
      "15    CCN1N=NN(CCN2CCC(CC2)(COC)N(C(=O)CC)c3ccccc3)C1=O\n",
      "16    CN(C)C(=O)C(CCN1CCC(O)(CC1)c1ccc(Cl)cc1)(c1ccc...\n",
      "17               CN1C2CCC1CC(C2)OC(=O)[C@H](CO)c3ccccc3\n",
      "18    COc1ccc(Cl)cc1C(=O)NCCc2ccc(cc2)[S](=O)(=O)NC(...\n",
      "19                         Nc1nnc(c(N)n1)c2cccc(Cl)c2Cl\n",
      "Name: smiles, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from utils import *\n",
    "from matplotlib import colors\n",
    "from rdkit.Chem.Draw import MolToImage\n",
    "\n",
    "# check the data frame\n",
    "drug_data.head()\n",
    "\n",
    "#extract smiles from the data frame and check the first 10 smiles\n",
    "smiles = drug_data['smiles']\n",
    "smiles.head()\n",
    "\n",
    "#convert smiles to mols and disable warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "mols\n",
    "print (type(mols[0]))\n",
    "\n",
    "#resizing the drug_data to \n",
    "end_of_array = 20\n",
    "smiles=smiles[:end_of_array]\n",
    "print(smiles)\n",
    "\n",
    "# Create a graph representation of the first molecule\n",
    "for i in range(0, end_of_array):\n",
    "    name = drug_data['name'][i]\n",
    "    img = get_image(mols[i],None , name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First object in the data_list: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "# Load the smiles and create the graph representation\n",
    "smiles = drug_data['smiles'].to_list()\n",
    "# Resize the array\n",
    "smiles = smiles[:end_of_array]\n",
    "\n",
    "# Load the labels we don't want to use them for training the autoencoder\n",
    "labels = drug_data['p_np'].to_list()\n",
    "# Resize the array\n",
    "labels = labels[:end_of_array]\n",
    "\n",
    "\n",
    "# Create a list of PyTorch Geometric Data objects\n",
    "data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(smiles, labels)\n",
    "print (\"First object in the data_list: \" + str(data_list[0].x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "import random\n",
    "random.shuffle(data_list)\n",
    "train = data_list[:int(len(data_list)*0.8)] #train set\n",
    "test = data_list[int(len(data_list)*0.2):] #val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model encoder\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    \n",
    "class GAE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2*out_channels)\n",
    "        self.conv2 = GCNConv(2*out_channels, out_channels)\n",
    "        self.conv3 = GCNConv(out_channels, in_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features (used as input): 79\n",
      "out channels: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n",
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = data_list[0].x.shape[1] #input to the encoder\n",
    "print(\"num_features (used as input): \" + str(num_features))\n",
    "print(\"out channels: \" + str(out_channels))\n",
    "epochs = 100\n",
    "model = GAE(num_features, out_channels)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n",
    "model = model.to(device) #create network and send to the device memory\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) #use Adam optimizer\n",
    "CSE = CrossEntropyLoss() #define loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: Data(x=[44, 79], edge_index=[2, 96], edge_attr=[96, 10], y=[1])\n",
      "out: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0080,  0.0001,  0.0039,  ...,  0.0120, -0.0077, -0.0107],\n",
      "        [ 0.0251,  0.0007,  0.0122,  ...,  0.0379, -0.0243, -0.0337],\n",
      "        ...,\n",
      "        [ 0.0387, -0.0010,  0.0197,  ...,  0.0563, -0.0366, -0.0508],\n",
      "        [ 0.0465, -0.0007,  0.0234,  ...,  0.0681, -0.0442, -0.0612],\n",
      "        [ 0.0390, -0.0012,  0.0199,  ...,  0.0566, -0.0368, -0.0511]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3]' is invalid for input of size 3476",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     num_correct += 1\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mout: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out))\n\u001b[0;32m---> 16\u001b[0m loss \u001b[39m=\u001b[39m CSE(torch\u001b[39m.\u001b[39;49mreshape(out, [\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m]), torch\u001b[39m.\u001b[39mreshape(torch\u001b[39m.\u001b[39margmax(data\u001b[39m.\u001b[39my),[\u001b[39m1\u001b[39m])) \u001b[39m#compute mean squared error loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sum_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(loss) \u001b[39m#add loss value to aggregate loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m#compute gradients\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 3]' is invalid for input of size 3476"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "from tqdm import tqdm\n",
    "model.train() #set model to training mode\n",
    "for epoch in range(2): #run for epochs of training\n",
    "    sum_loss = 0 #used to compute average loss in an epoch\n",
    "    num_correct = 0\n",
    "    random.shuffle(train) #shuffle the training data each epoch\n",
    "    for d in tqdm(train): #go over each training point\n",
    "        data = d.to(device) #send data to device\n",
    "        print(\"data: \" + str(data))\n",
    "        optimizer.zero_grad() #zero gradients\n",
    "        out = model(data) #evaluate data point\n",
    "        # if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n",
    "        #     num_correct += 1\n",
    "        print(\"out: \" + str(out))\n",
    "        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n",
    "        sum_loss += float(loss) #add loss value to aggregate loss\n",
    "        loss.backward() #compute gradients\n",
    "        optimizer.step() #apply optimization\n",
    "    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e71e0c1465a0fac3e495801f7a6fb448cef63610b0348ba82fb26a800360512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
