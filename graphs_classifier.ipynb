{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Studying data\n",
        "The blood-brain barrier (BBB) controls the entry of chemicals from the blood to the brain. Since brain drugs need to penetrate the BBB, rapid and reliable prediction of BBB penetration (BBBP) is helpful for drug development. In this study, free-form and in-blood-form datasets were prepared by modifying the original BBBP dataset, and the effects of the data modification were investigated.\n",
        "\n",
        "The original BBBP dataset contains 2053 items with four attributes: the index number from 1 to 2053 (“num”), the name of the compound (“name”), the penetrating or non-penetrating properties (“p_np”), and the SMILES string of the compound (“smiles”).\n",
        "\n",
        "Sakiyama H, Fukuda M, Okuno T. Prediction of Blood-Brain Barrier Penetration (BBBP) Based on Molecular Descriptors of the Free-Form and In-Blood-Form Datasets. Molecules. 2021 Dec 7;26(24):7428. doi: 10.3390/molecules26247428. PMID: 34946509; PMCID: PMC8708321.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of unitary p_np values:  1567\n",
            "Total number of zero p_np values:  483\n",
            "Total number of p_np values:  2050\n",
            "Percentage of unitary p_np values:  76.44 %\n",
            "Percentage of zero p_np values:  23.56 %\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in the data\n",
        "drug_data=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "#sum all values equal to 1 in p_np column of drug_data\n",
        "total_unitary_pnp = sum(drug_data.p_np==1)\n",
        "print (\"Total number of unitary p_np values: \", total_unitary_pnp)\n",
        "\n",
        "#sum all values equal to 0 in p_np column of drug_data\n",
        "total_zero_pnp = sum(drug_data.p_np==0)\n",
        "print (\"Total number of zero p_np values: \", total_zero_pnp)\n",
        "\n",
        "# Print the total number of p_np values\n",
        "print (\"Total number of p_np values: \", len(drug_data.p_np))\n",
        "\n",
        "# Calculate the percentage of unitary p_np values\n",
        "print (\"Percentage of unitary p_np values: \", round(total_unitary_pnp*100/len(drug_data.p_np),2), \"%\")\n",
        "\n",
        "#calculate the percentage of zero p_np values\n",
        "print (\"Percentage of zero p_np values: \", round (total_zero_pnp*100/len(drug_data.p_np),2), \"%\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Watching data in more detail to be given to GAE\n",
        "\n",
        "The GAE should classify in two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'rdkit.Chem.rdchem.Mol'>\n",
            "0                     [Cl].CC(C)NCC(O)COc1cccc2ccccc12\n",
            "1             C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl\n",
            "2    c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...\n",
            "3                     C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C\n",
            "4    Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...\n",
            "5    CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(...\n",
            "6    CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@...\n",
            "7                  Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14\n",
            "8    COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@...\n",
            "9                         NC(N)=NC(=O)c1nc(Cl)c(N)nc1N\n",
            "Name: smiles, dtype: object\n"
          ]
        }
      ],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit import RDLogger\n",
        "from utils import *\n",
        "from matplotlib import colors\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "\n",
        "# check the data frame\n",
        "drug_data.head()\n",
        "\n",
        "#extract smiles from the data frame and check the first 10 smiles\n",
        "smiles = drug_data['smiles']\n",
        "smiles.head()\n",
        "\n",
        "#convert smiles to mols and disable warnings\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
        "mols\n",
        "print (type(mols[0]))\n",
        "\n",
        "#resizing the drug_data to \n",
        "end_of_array = 10\n",
        "smiles=smiles[:end_of_array]\n",
        "print(smiles)\n",
        "\n",
        "# Create a graph representation of the first molecule\n",
        "for i in range(0, end_of_array):\n",
        "    name = drug_data['name'][i]\n",
        "    img = get_image(mols[i],None , name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[Cl].CC(C)NCC(O)COc1cccc2ccccc12', 'C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl', 'c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO3)=O', 'C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C', 'Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C(O)=O', 'CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(N3C2=O)C(O)=O)CSc4nnnn4C)c5ccc(O)cc5)C(=O)C1=O', 'CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@@]3(C)O)C(=O)[C@]2(O)C(=O)\\\\C(=C(/O)NCN5CCCC5)C1=O', 'Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14', 'COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@@H]2OC(C)=O', 'NC(N)=NC(=O)c1nc(Cl)c(N)nc1N']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Data(x=[20, 79], edge_index=[2, 40], edge_attr=[40, 10], y=[1])\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x288ca5060>\n",
            "Data(x=[20, 79], edge_index=[2, 40], edge_attr=[40, 10], y=[1])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'GAE' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[56], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m in_channels \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m out_channels \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[0;32m---> 35\u001b[0m model \u001b[39m=\u001b[39m GAE(in_channels, out_channels) \n",
            "\u001b[0;31mNameError\u001b[0m: name 'GAE' is not defined"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import networkx as nx\n",
        "# Load the drug data and create the graph representation\n",
        "smiles = drug_data['smiles'].to_list()\n",
        "smiles = smiles[:end_of_array]\n",
        "print (smiles)\n",
        "labels = drug_data['p_np'].to_list()\n",
        "labels = labels[:end_of_array]\n",
        "print (labels)\n",
        "data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(smiles, labels)\n",
        "print (data_list[0])\n",
        "\n",
        "# Create a dataloader for training\n",
        "dataloader = DataLoader(dataset = data_list, batch_size = 2**7)\n",
        "print (dataloader)\n",
        "# Define the loss function\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_smiles):\n",
        "        self.data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles,labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_list[idx]\n",
        "    \n",
        "dataset = MyDataset(smiles)\n",
        "print (dataset[0])\n",
        "# Define the number of channels for the input and output of the model\n",
        "in_channels = dataset[0].x.shape[1]\n",
        "out_channels = 16\n",
        "\n",
        "model = GAE(in_channels, out_channels) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[Cl].CC(C)NCC(O)COc1cccc2ccccc12', 'C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl', 'c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO3)=O', 'C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C', 'Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C(O)=O', 'CCN1CCN(C(=O)N[C@@H](C(=O)N[C@H]2[C@H]3SCC(=C(N3C2=O)C(O)=O)CSc4nnnn4C)c5ccc(O)cc5)C(=O)C1=O', 'CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@@]3(C)O)C(=O)[C@]2(O)C(=O)\\\\C(=C(/O)NCN5CCCC5)C1=O', 'Cn1c2CCC(Cn3ccnc3C)C(=O)c2c4ccccc14', 'COc1ccc(cc1)[C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@@H]2OC(C)=O', 'NC(N)=NC(=O)c1nc(Cl)c(N)nc1N']\n",
            "creating graph\n",
            "graph created\n",
            "Epoch: 0\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(epoch))\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     35\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39miteration:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))\n\u001b[1;32m     36\u001b[0m         \u001b[39m# Extract the features and labels\u001b[39;00m\n",
            "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
            "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:151\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    149\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>"
          ]
        }
      ],
      "source": [
        "smiles = drug_data['smiles'].to_list()\n",
        "smiles = smiles[:end_of_array]\n",
        "print(smiles)\n",
        "#G = mols\n",
        "print (\"creating graph\")\n",
        "G = create_graph(drug_data['smiles'][:end_of_array])\n",
        "print (\"graph created\")\n",
        "\n",
        "dataloader = DataLoader(data_list , batch_size = 2**7)\n",
        "#print(dataloader)\n",
        "# Convert the graph to an adjacency matrix\n",
        "#A = nx.adjacency_matrix(G).todense()\n",
        "#print (\"adjacency matrix created\")\n",
        "#print (A)\n",
        "\n",
        "num_features = 50\n",
        "hidden_dim = 32\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "# print()\n",
        "# dataloader = DataLoader(A, batch_size=num_features, shuffle=False)\n",
        "\n",
        "# Define the model, criterion,\n",
        "model = GraphAutoencoder(input_dim=num_features, hidden_dim=hidden_dim, output_dim=num_features)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    print (\"Epoch: \" + str(epoch))\n",
        "    for i, data in enumerate(dataloader):\n",
        "        print(\"iteration:\" + str(i))\n",
        "        # Extract the features and labels\n",
        "        print(\"data before casting to float32:\")\n",
        "        print(data)\n",
        "        print(\"featrues and labels before casting to float32:\")\n",
        "        features, labels = data\n",
        "        # data = data.to(torch.float32)\n",
        "        # print(\"data after casting to float32:\")\n",
        "        # print(data)\n",
        "        # features, labels = data\n",
        "        # print(\"featrues and labels after casting to float32:\")\n",
        "        # print(features)\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(features)\n",
        "        loss = criterion(output, features)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Extract the embeddings from the trained model\n",
        "embeddings = model.encoder.weight.data.cpu().numpy()\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "z9h0cm2zLwwD",
        "outputId": "f1053ddc-0963-494b-85e6-491eb9651b89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c0bd131e-8699-4339-8a4e-0013f0743cbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c0bd131e-8699-4339-8a4e-0013f0743cbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (7).csv\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0e1a020eb30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m    \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m     return self.fit_generator(\n\u001b[0m\u001b[1;32m    352\u001b[0m         self.default_generator(dataset,\n\u001b[1;32m    353\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                                                    self.n_classes)\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mmultiConvMol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         inputs = [\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36magglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'atom_features'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import deepchem as dc\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "drugs=files.upload()\n",
        "drugs=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "# Load the MoleculeNet dataset\n",
        "tasks, datasets, transformers =  dc.molnet.load_muv()\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "# Build the model\n",
        "n_features = train_dataset.get_data_shape()[0]\n",
        "n_tasks = len(tasks)\n",
        "graph_conv_filters = [[64,64], [128,128]]\n",
        "dense_layer_size = 128\n",
        "\n",
        "# Create the graph autoencoder model\n",
        "model = dc.models.GraphConvModel(n_tasks, graph_conv_filters, dense_layer_size,\n",
        "                                 batch_size=128, learning_rate=1e-4)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "\n",
        "# Evaluate the model\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "print(model.evaluate(test_dataset, [metric], transformers))\n",
        "\n",
        "# Get the embeddings\n",
        "embeddings = model.get_embeddings(train_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LarxkR-jHz_z",
        "outputId": "411ad930-6d2d-4639-bd50-7b7507deb43c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7290a612-01a1-4be4-b2c9-2952fcad331b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7290a612-01a1-4be4-b2c9-2952fcad331b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.data.data_loader:smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 59, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 61, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (15).csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 391, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 614, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 642, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 645, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 646, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 647, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 648, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 649, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 685, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 59, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 61, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 391, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 614, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 642, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 645, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 646, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 647, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 648, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 649, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 685, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3e9ba554f6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mfeaturizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvMolFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiskDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtest_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataset, transformers, outputs, output_types)\u001b[0m\n\u001b[1;32m    823\u001b[0m                                        \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                                        pad_batches=False)\n\u001b[0;32m--> 825\u001b[0;31m     return self.predict_on_generator(generator,\n\u001b[0m\u001b[1;32m    826\u001b[0m                                      \u001b[0mtransformers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                                      \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mpredict_on_generator\u001b[0;34m(self, generator, transformers, outputs, output_types)\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mproduces\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \"\"\"\n\u001b[0;32m--> 730\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m   def predict_on_batch(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, generator, transformers, outputs, uncertainty, other_output_types)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                                                    self.n_classes)\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mmultiConvMol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         inputs = [\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36magglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'atom_features'"
          ]
        }
      ],
      "source": [
        "import deepchem as dc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the drug dataset\n",
        "from google.colab import files\n",
        "data=files.upload()\n",
        "data=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "smiles = data['smiles'].to_list()\n",
        "\n",
        "# Featurizing the data\n",
        "\n",
        "\n",
        "# Splitting the data into train, validation and test\n",
        "\n",
        "tasks = ['p_np']\n",
        "\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "loader = dc.data.CSVLoader(\n",
        "    tasks=tasks, smiles_field=\"smiles\", featurizer=featurizer)\n",
        "dataset = loader.featurize(\"BBBP.csv\")\n",
        "X = featurizer.featurize(smiles)\n",
        "\n",
        "# Splitting the data into train, validation and test\n",
        "y = data['p_np'].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Initializing the model \n",
        "model = dc.models.GraphConvModel(len(tasks), batch_size=50, mode=\"regression\")\n",
        "train_dataset = dc.data.NumpyDataset(X_train, y_train)\n",
        "test_dataset = dc.data.NumpyDataset(X_test, y_test)\n",
        "tasks = ['p_np']\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "test_dataset = dc.data.DiskDataset.from_dataframe(data, tasks)\n",
        "test_embeddings = model.predict(test_dataset)\n",
        "\n",
        "\n",
        "# Get the embeddings for the test set\n",
        "\n",
        "\n",
        "print(test_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPMC78pPIKrp",
        "outputId": "76abfe92-a4ae-4af8-c2ab-029409e43207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.0.2)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2022.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: rdkit, deepchem\n",
            "Successfully installed deepchem-2.7.1 rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "_dJOAt9RUPYV",
        "outputId": "5d171979-22f8-45fe-d964-496a9be46407"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d32778d3-19b7-4b49-baae-d022022b67dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d32778d3-19b7-4b49-baae-d022022b67dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (2).csv\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.8.8)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
            "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n",
            "/usr/local/lib/python3.8/dist-packages/dgl/heterograph.py:354: DGLWarning: DGLGraph.add_edge is deprecated. Please use DGLGraph.add_edges\n",
            "  dgl_warning(\"DGLGraph.add_edge is deprecated. Please use DGLGraph.add_edges\")\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a0ee1b567ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u, v, data, etype)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0mdgl_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DGLGraph.add_edge is deprecated. Please use DGLGraph.add_edges\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36madd_edges\u001b[0;34m(self, u, v, data, etype)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO(xiangsx): block do not support add_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/utils/checks.py\u001b[0m in \u001b[0;36mprepare_tensor\u001b[0;34m(g, data, name)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         if (not (F.ndim(data) > 0 and F.shape(data)[0] == 0) and        # empty tensor\n\u001b[1;32m     43\u001b[0m                 F.dtype(data) not in (F.int32, F.int64)):\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(data, dtype)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mas_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "smiles=df['smiles']\n",
        "!pip install dgl\n",
        "!pip install torch\n",
        "import dgl\n",
        "import torch\n",
        "\n",
        "g = dgl.DGLGraph()\n",
        "# Add nodes to the graph\n",
        "g.add_nodes(len(df))\n",
        "\n",
        "# Add edges to the graph\n",
        "for i, row in df.iterrows():\n",
        "  for j, col in row.iteritems():\n",
        "    if i != j and col == 1:\n",
        "      g.add_edge(i, j)\n",
        "import torch.nn as nn\n",
        "\n",
        "class GraphAutoEncoder(nn.Module):\n",
        "  def _init_(self, in_dim, hidden_dim, out_dim):\n",
        "    super(GraphAutoEncoder, self)._init_()\n",
        "    self.encoder = nn.Linear(in_dim, hidden_dim)\n",
        "    self.decoder = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "def smiles_to_fingerprint(smiles):\n",
        "  # Convert the SMILES string to a RDKit molecule\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "  # Calculate the Morgan fingerprint for the molecule\n",
        "  fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
        "\n",
        "  # Convert the fingerprint to a NumPy array\n",
        "  fingerprint = np.array(fingerprint)\n",
        "\n",
        "  return fingerprint\n",
        "\n",
        "# Convert the SMILES strings in the BBBP dataset to fingerprints\n",
        "fingerprints = df['smiles'].apply(smiles_to_fingerprint)\n",
        "\n",
        "# Convert the fingerprints to a NumPy array\n",
        "X = np.stack(fingerprints.values)\n",
        "in_dim = X.shape[1]\n",
        "out_dim = X.shape[1]\n",
        "\n",
        "\n",
        "# Create an instance of the GraphAutoEncoder model\n",
        "model = GraphAutoEncoder(in_dim=df.shape[1], hidden_dim=64, out_dim=df.shape[1])\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "# Loop over the number of epochs\n",
        "for epoch in range(100):\n",
        "  # Clear the gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # # Extract the encoder part of the model\n",
        "encoder = model.encoder\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Transform the input data into the latent space\n",
        "latent = encoder(torch.Tensor(df.values))\n",
        "embedding = latent.detach().numpy()\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "def smiles_to_fingerprint(smiles):\n",
        "  # Convert the SMILES string to a RDKit molecule\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "  # Calculate the Morgan fingerprint for the molecule\n",
        "  fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
        "\n",
        "  # Convert the fingerprint to a NumPy array\n",
        "  fingerprint = np.array(fingerprint)\n",
        "\n",
        "  return fingerprint\n",
        "\n",
        "# Convert the SMILES strings in the BBBP dataset to fingerprints\n",
        "fingerprints = df['smiles'].apply(smiles_to_fingerprint)\n",
        "\n",
        "# Convert the fingerprints to a NumPy array\n",
        "X = np.stack(fingerprints.values)\n",
        "in_dim = X.shape[1]\n",
        "out_dim = X.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZgkgLT6WN9D",
        "outputId": "9b13a4b6-8c7d-4aa8-c269-b93b550a2a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N38wygO0Qvks",
        "outputId": "2c2ac774-775e-4642-da1e-b6091a032b8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 59, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 61, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 391, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 614, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 642, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 645, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 646, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 647, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 648, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 649, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 685, None. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: Python argument types in\n",
            "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
            "did not match C++ signature:\n",
            "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
            "/usr/local/lib/python3.8/dist-packages/deepchem/feat/base_classes.py:323: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.asarray(features)\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ef72a445fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m    \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m     return self.fit_generator(\n\u001b[0m\u001b[1;32m    352\u001b[0m         self.default_generator(dataset,\n\u001b[1;32m    353\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                                                    self.n_classes)\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mmultiConvMol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         inputs = [\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36magglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Combine the features, then sort them by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'atom_features'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import deepchem as dc\n",
        "\n",
        "# Load the BBBP dataset\n",
        "tasks, datasets, transformers = dc.molnet.load_bbbp()\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "# Build the model\n",
        "n_features = train_dataset.get_data_shape()[0]\n",
        "n_tasks = len(tasks)\n",
        "graph_conv_filters = [[64,64], [128,128]]\n",
        "dense_layer_size = 128\n",
        "\n",
        "# Create the graph autoencoder model\n",
        "model = dc.models.GraphConvModel(n_tasks, graph_conv_filters, dense_layer_size,\n",
        "                                 batch_size=128, learning_rate=1e-4)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "\n",
        "# Evaluate the model\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "print(model.evaluate(test_dataset, [metric], transformers))\n",
        "\n",
        "# Get the embeddings\n",
        "embeddings = model.get_embeddings(train_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "uPExtiitZ7wH",
        "outputId": "2f095cce-c66a-41ae-a0e7-864dab167c34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-25854879-f8ef-4b4e-8cb4-f5e9a86fe1b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-25854879-f8ef-4b4e-8cb4-f5e9a86fe1b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (26).csv\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-94eca193a172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0m\u001b[1;32m     20\u001b[0m                                         self.exclude_keys)\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     74\u001b[0m         Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         batch, slice_dict, inc_dict = collate(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdata_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Collate attributes into a unified representation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             value, slices, incs = _collate(attr, values, data_list, stores,\n\u001b[0m\u001b[1;32m     85\u001b[0m                                            increment)\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 19 but got size 39 for tensor number 1 in the list."
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"HIV.csv\")\n",
        "smiles_list=df['smiles']\n",
        "\n",
        "\n",
        "\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "def get_mol_graph(smiles):\n",
        "  # Use RDKit to parse the SMILES string and get the molecular graph\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  if mol is None: return None\n",
        "  adjacency_matrix = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "  atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "  return adjacency_matrix, atoms\n",
        "  \n",
        "  \n",
        "valid_smiles = list(filter(lambda x: Chem.MolFromSmiles(x) is not None, smiles_list))\n",
        "\n",
        "\n",
        "def get_data_from_smiles(valid_smiles):\n",
        "  data_list = []\n",
        "  for smiles in smiles_list:\n",
        "    graph = get_mol_graph(smiles)\n",
        "    if graph is not None:\n",
        "      data_list.append(Data(x=torch.tensor(graph[1]).unsqueeze(0), edge_index=torch.tensor(graph[0]).unsqueeze(0)))\n",
        "  return data_list\n",
        "  import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "def get_mol_graph(valid_smiles):\n",
        "    mol = Chem.MolFromSmiles(valid_smiles)\n",
        "    if mol is None: return None\n",
        "    adjacency_matrix = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "    atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "    return adjacency_matrix, atoms\n",
        "\n",
        "def get_data_from_smiles(valid_smiles):\n",
        "    data_list = []\n",
        "    for smiles in valid_smiles:\n",
        "        graph = get_mol_graph(smiles)\n",
        "        if graph is not None:\n",
        "            data_list.append(Data(x=torch.tensor(graph[1]).unsqueeze(0), edge_index=torch.tensor(graph[0]).unsqueeze(0)))\n",
        "    return data_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GraphAutoEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim):\n",
        "    super(GraphAutoEncoder, self).__init__()\n",
        "    self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "    self.conv2 = GCNConv(hidden_dim, input_dim)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    return x\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set the random seed\n",
        "random.seed\n",
        "# Load the model and move it to the appropriate device\n",
        "input_dim = 50\n",
        "hidden_dim = 32\n",
        "model = GraphAutoEncoder(input_dim, hidden_dim).to(device)\n",
        "\n",
        "\n",
        "# Load the input data\n",
        "data = get_data_from_smiles(smiles_list)\n",
        "\n",
        "# Extract the embeddings\n",
        "# Extract the embeddings\n",
        "batch_size = len(valid_smiles) \n",
        "hidden_dim = 32.\n",
        "embeddings = []\n",
        "data_loader = DataLoader(data, batch_size=len(data), shuffle=False)\n",
        "\n",
        "for i, datum in enumerate(data_loader):\n",
        "    datum.to(device)\n",
        "    embeddings.append(model.conv1(datum.x, datum.edge_index))\n",
        "    \n",
        "# Print the embeddings\n",
        "print(embeddings)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "M2ERyy_LWRig",
        "outputId": "a025ddc6-db29-48f0-ffbe-ca6e0ab42edc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.8/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f2e0ae299725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerXM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiskDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TransformerXM' from 'deepchem.models' (/usr/local/lib/python3.8/dist-packages/deepchem/models/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from deepchem.models import TransformerXM\n",
        "from deepchem.utils import get_features\n",
        "from deepchem.data import DiskDataset\n",
        "\n",
        "# load dataset\n",
        "tasks = [\"p_np\"]\n",
        "from google.colab import files\n",
        "\n",
        "data = files.upload()\n",
        "import pandas as pd\n",
        "data=pd.read_csv(\"BBBP.csv\")\n",
        "data = pd.read_csv(\"BBBP.csv\")\n",
        "X = get_features(data.smiles)\n",
        "y = data[tasks].values\n",
        "dataset = DiskDataset.from_numpy(X, y, w=None, ids=None)\n",
        "\n",
        "# Split the dataset\n",
        "splitter = dc.splits.RandomSplitter()\n",
        "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset)\n",
        "\n",
        "# Build the model\n",
        "n_embedding = 128\n",
        "model = TransformerXM(n_embedding=n_embedding, n_layers=3, n_heads=4, batch_size=32,\n",
        "                      dropout=0.1, use_attn_loss=True, use_mask=True)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.embed(dataset)\n",
        "\n",
        "# Print the embeddings\n",
        "print(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "EJ7dhjfRYtrK",
        "outputId": "bb9c406b-769d-49fa-ee87-0c2f8a3d9a0a"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e03d5f5bc520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphAutoEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GraphAutoEncoder' from 'deepchem.models' (/usr/local/lib/python3.8/dist-packages/deepchem/models/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from deepchem.models import GraphAutoEncoder\n",
        "from deepchem.utils import get_features\n",
        "\n",
        "# load dataset\n",
        "from google.colab import files\n",
        "\n",
        "data = files.upload()\n",
        "import pandas as pd\n",
        "data=pd.read_csv(\"BBBP.csv\")\n",
        "data = pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "X = get_features(data.smiles)\n",
        "\n",
        "# Build the model\n",
        "latent_dim = 256\n",
        "model = GraphAutoEncoder(latent_dim, graph_conv_layers=[64, 64], \n",
        "                         generator_layers=[512, 512])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, nb_epoch=100)\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(X)\n",
        "\n",
        "# Print the embeddings\n",
        "print(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rqLF-wQZj4j"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv, Autoencoder\n",
        "import torch.nn.functional as F\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import QM9\n",
        "\n",
        "class Autoencoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, in_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Prepare the dataset\n",
        "mols = []\n",
        "for i in range(50000):\n",
        "    mols.append(Chem.MolFromSmiles(qm9[i][\"smiles\"]))\n",
        "\n",
        "data = []\n",
        "for i, mol in enumerate(mols):\n",
        "    mol = mol.GetMol()\n",
        "    if mol is None:\n",
        "        continue\n",
        "    x = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol)\n",
        "    x = np.array(x)\n",
        "    x = x / np.sum(x)\n",
        "    edge_index = Chem.GetAdjacencyMatrix(mol).nonzero()\n",
        "    edge_index = torch.tensor(np.array(edge_index).T, dtype=torch.long)\n",
        "    data.append(Data(x=torch.tensor(x, dtype=torch.float), edge_index=edge_index))\n",
        "\n",
        "#Build the Autoencoder model\n",
        "model = Autoencoder(16, 256)\n",
        "model = model.cuda()\n",
        "\n",
        "# Fit the model\n",
        "for i in range(100):\n",
        "    for data in data:\n",
        "        data = data.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        x_hat = model(data.x, data.edge)\n",
        "        def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "x = F.relu(x)\n",
        "x = self.conv2(x, edge_index)\n",
        "encoded = self.conv1.weight\n",
        " return x, encoded\n",
        "embeddings = model(data.x, data.edge_index)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "d1tSmG_tastz",
        "outputId": "174843d4-680a-4d32-dc57-b5081d79845b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-0.9.1-cp38-cp38-manylinux1_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.8.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Installing collected packages: psutil, dgl\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-0.9.1 psutil-5.9.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VF6fGoq7bGNt",
        "outputId": "2527aceb-12a0-4d5b-ae37-e575df22e881"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e4d43fc51f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMILESGraphDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from dgl.data import SMILESGraphDataset\n",
        "from google.colab import files\n",
        "\n",
        "dataset = files.upload()\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "# Prepare the dataset\n",
        "dataset = SMILESGraphDataset(\"BBBP.csv\")\n",
        "\n",
        "# Define the Graph Auto-Encoder model\n",
        "class GAE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size, k):\n",
        "        super(GAE, self).__init__()\n",
        "        self.conv1 = dgl.nn.SAGEConv(in_feats, hidden_size, k)\n",
        "        self.conv2 = dgl.nn.SAGEConv(hidden_size, hidden_size, k)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, in_feats)\n",
        "\n",
        "    def forward(self, g):\n",
        "        g.ndata['h'] = g.ndata['x']\n",
        "        g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
        "        g.ndata['h'] = self.conv1(g, g.ndata['h'])\n",
        "    def forward(self, g):\n",
        "        g.ndata['h'] = g.ndata['x']\n",
        "        g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
        "        g.ndata['h'] = self.conv1(g, g.ndata['h'])\n",
        "        g.ndata['h'] = self.fc1(g.ndata['h'])\n",
        "        embeddings = g.ndata['h']\n",
        "        return embeddings\n",
        "print(embeddings)\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "MttIi83Kxm8t",
        "outputId": "37a67016-3538-4bd6-b753-bd5f24ee6096"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.8/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1430b2a36c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphConvModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmiles_to_bigraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_missing_entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'smiles_to_bigraph' from 'deepchem.feat' (/usr/local/lib/python3.8/dist-packages/deepchem/feat/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import deepchem as dc\n",
        "from deepchem.models import GraphConvModel\n",
        "from deepchem.feat import smiles_to_bigraph\n",
        "from deepchem.utils import remove_missing_entries\n",
        "from deepchem.utils.evaluate import Evaluator\n",
        "from rdkit import Chem\n",
        "\n",
        "# Load your drug dataset as a Pandas dataframe\n",
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "# Convert SMILES strings to molecular graphs\n",
        "mols = df['smiles'].apply(Chem.MolFromSmiles)\n",
        "bigraphs = smiles_to_bigraph(mols)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train_frac = 0.8\n",
        "valid_frac = 0.1\n",
        "test_frac = 0.1\n",
        "splitters = {\n",
        "    'train': train_frac,\n",
        "    'valid': valid_frac,\n",
        "    'test': test_frac\n",
        "}\n",
        "dataset = dc.data.NumpyDataset(bigraphs,df['p_np'],  splitters=splitters)\n",
        "\n",
        "# Create a GraphConvModel for training\n",
        "model = GraphConvModel(n_tasks=1, mode='classification', dropout=0.2)\n",
        "\n",
        "# Fit the model to the dataset\n",
        "model.fit(dataset, nb_epoch=10)\n",
        "\n",
        "# Extract the embeddings of the molecules\n",
        "embeddings = model.get_embeddings(dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "seoSK9NqzeQB",
        "outputId": "f622044a-2aa5-4c10-eb1d-bd0febc0a94c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ad423db-9688-4722-a129-b84dfc57df83\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ad423db-9688-4722-a129-b84dfc57df83\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (21).csv\n",
            "Original length of smiles array:  2050\n",
            "Original length of activity array:  2050\n",
            "Valid length of smiles array:  2039\n",
            "Valid length of activity array:  2039\n",
            "train_dataset X shape:  (2039,)\n",
            "train_dataset y shape:  (1631,)\n",
            "valid_dataset X shape:  (204,)\n",
            "valid_dataset y shape:  (204,)\n",
            "test_dataset X shape:  (204,)\n",
            "test_dataset y shape:  (204,)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-20529a939ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m    \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m     return self.fit_generator(\n\u001b[0m\u001b[1;32m    352\u001b[0m         self.default_generator(dataset,\n\u001b[1;32m    353\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                         pad_batches=True):\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m       for (X_b, y_b, w_b,\n\u001b[0m\u001b[1;32m   1007\u001b[0m            \u001b[0mids_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterbatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                                          \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/deepchem/data/datasets.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(dataset, batch_size, epochs, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    883\u001b[0m           \u001b[0mperm_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_perm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m           \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m           \u001b[0mw_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0mids_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1885 is out of bounds for axis 0 with size 1631"
          ]
        }
      ],
      "source": [
        "\n",
        "import deepchem as dc\n",
        "from deepchem.models import GraphConvModel\n",
        "\n",
        "from deepchem.utils import remove_missing_entries\n",
        "from deepchem.utils.evaluate import Evaluator\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "\n",
        "# Print the length of the arrays before removing invalid SMILES strings\n",
        "print(\"Original length of smiles array: \", len(df['smiles']))\n",
        "print(\"Original length of activity array: \", len(df['p_np']))\n",
        "\n",
        "# Remove invalid SMILES strings\n",
        "valid_smiles = []\n",
        "valid_activity = []\n",
        "for i,smiles in enumerate(df['smiles']):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol != None:\n",
        "            valid_smiles.append(smiles)\n",
        "            valid_activity.append(df['p_np'][i])\n",
        "    except:\n",
        "        continue\n",
        "        \n",
        "# Print the length of the arrays after removing invalid SMILES strings\n",
        "print(\"Valid length of smiles array: \", len(valid_smiles))\n",
        "print(\"Valid length of activity array: \", len(valid_activity))\n",
        "dataset = dc.data.NumpyDataset(valid_smiles, valid_activity)\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "train_data = featurizer.featurize(valid_smiles)\n",
        "train_dataset = dc.data.NumpyDataset(train_data, valid_activity)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from deepchem.splits import RandomSplitter\n",
        "scaffold_splitter = RandomSplitter()\n",
        "train_frac = 0.8\n",
        "valid_frac = 0.1\n",
        "test_frac = 0.1\n",
        "dataset = dc.data.NumpyDataset(valid_smiles, valid_activity)\n",
        "train_dataset, valid_dataset, test_dataset = scaffold_splitter.train_valid_test_split(dataset, train_frac, valid_frac, test_frac)\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "train_data = featurizer.featurize(valid_smiles)\n",
        "train_dataset = dc.data.NumpyDataset(train_data, train_dataset.y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the shapes of the arrays in the datasets\n",
        "print(\"train_dataset X shape: \", train_dataset.X.shape)\n",
        "print(\"train_dataset y shape: \", train_dataset.y.shape)\n",
        "print(\"valid_dataset X shape: \", valid_dataset.X.shape)\n",
        "print(\"valid_dataset y shape: \", valid_dataset.y.shape)\n",
        "print(\"test_dataset X shape: \", test_dataset.X.shape)\n",
        "print(\"test_dataset y shape: \", test_dataset.y.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a GraphConvModel for training\n",
        "model = GraphConvModel(n_tasks=1, mode='classification', dropout=0.2)\n",
        "\n",
        "\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "train_data = featurizer.featurize(valid_smiles)\n",
        "train_X_reshaped = train_dataset.X.reshape((train_dataset.X.shape[0], -1))\n",
        "train_y_reshaped = train_dataset.y.reshape((train_dataset.y.shape[0], -1))\n",
        "train_dataset_reshaped = dc.data.NumpyDataset(train_X_reshaped, train_y_reshaped)\n",
        "\n",
        "valid_X_reshaped = valid_dataset.X.reshape((valid_dataset.X.shape[0], -1))\n",
        "valid_y_reshaped = valid_dataset.y.reshape((valid_dataset.y.shape[0], -1))\n",
        "valid_dataset_reshaped = dc.data.NumpyDataset(valid_X_reshaped, valid_y_reshaped)\n",
        "\n",
        "\n",
        "\n",
        "model = GraphConvModel(n_tasks=1, mode='classification', dropout=0.2)\n",
        "model.fit(train_dataset, nb_epoch=10)\n",
        "\n",
        "\n",
        "# Extract the embeddings of the molecules\n",
        "from keras.layers import Input, Dropout\n",
        "from deepchem.models import GraphConvModel\n",
        "print(train_data.shape)\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(None, train_data.shape[2], train_data.shape[3]), name=\"input_layer\")\n",
        "\n",
        "output_embedding = model.get_layer(index=-2)(input_layer)\n",
        "embedding_model = model(input_layer, output_embedding)\n",
        "embeddings = embedding_model.predict(dataset.X)\n",
        "print(embeddings)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "1dmTelpWEO3J",
        "outputId": "a8d48cdb-f688-43fe-9b3a-0812146d2602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43acd83d-77b7-46a5-a667-a397fabebd47\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43acd83d-77b7-46a5-a667-a397fabebd47\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (4).csv\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f18576f7cda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f18576f7cda0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Encoder' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as gnn\n",
        "from torch_geometric.data import Data\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "valid_smiles = []\n",
        "for smiles in df[\"smiles\"]:\n",
        "\n",
        "                                  mol = Chem.MolFromSmiles(smiles)\n",
        "                                  if mol is not None:\n",
        "                                   valid_smiles.append(smiles)\n",
        "def smiles_to_graph(valid_smiles):\n",
        "    mol = Chem.MolFromSmiles(valid_smiles)\n",
        "    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "    x = mol.GetConformer().GetPositions()\n",
        "    edge_index = torch.nonzero(adj)\n",
        "    return Data(x=torch.tensor(x), edge_index=edge_index)\n",
        "    class Encoder(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Encoder, self).__init__()\n",
        "            self.conv1 = gnn.GCNConv(3, 64)\n",
        "            self.conv2 = gnn.GCNConv(64, 128)\n",
        "def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.conv1 = gnn.GCNConv(128, 64)\n",
        "        self.conv2 = gnn.GCNConv(64, 3)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    def forward(self, data):\n",
        "        x = self.encoder(data)\n",
        "        x = self.decoder(x, data.edge_index)\n",
        "        return x\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters())\n",
        "# Convert a new SMILES string to a graph\n",
        "for smiles in valid_smiles:\n",
        "                          graph = smiles_to_graph(smiles)\n",
        "\n",
        "# Pass the graph through the encoder to generate an embedding\n",
        "embedding = autoencoder.encoder(graph)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "UaqfyG4hUnj_",
        "outputId": "d78b44be-a2a8-4993-fe32-381cd613566f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6fe38c8-dd4a-4ef5-b569-f9a5eb2e6247\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6fe38c8-dd4a-4ef5-b569-f9a5eb2e6247\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (6).csv\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2e29c5f9f8e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-239fdff98328>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0min_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2039\u001b[0m \u001b[0;31m# example value, you should use the size of your fingerprints representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0;32m--> 177\u001b[0;31m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n\u001b[1;32m    179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "from rdkit import Chem\n",
        "\n",
        "# Create an empty list to store the valid SMILES strings\n",
        "valid_smiles = []\n",
        "\n",
        "# Iterate through all the SMILES strings in your dataset\n",
        "for smiles in df[\"smiles\"]:\n",
        "    # Attempt to parse the SMILES string using the RDKit\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # If the SMILES string is valid, add it to the list of valid SMILES\n",
        "    if mol is not None:\n",
        "        valid_smiles.append(smiles)\n",
        "    # If the SMILES string is invalid, it will return None and you can ignore it\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
        "\n",
        "class GF_VAE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size):\n",
        "        super(GF_VAE, self).__init__()\n",
        "        self.encoder = GCNConv(in_feats, hidden_size)\n",
        "        self.decoder = GAE(hidden_size, in_feats)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        z = self.encoder(x, edge_index)\n",
        "        return self.decoder(z, edge_index), z\n",
        "in_feats = 2039 # example value, you should use the size of your fingerprints representation\n",
        "hidden_size = 128 \n",
        "\n",
        "# create the model\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs\n",
        "\n",
        "fingerprints = []\n",
        "for smiles in valid_smiles:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # calculate morgan fingerprint\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
        "    arr = np.zeros((1,))\n",
        "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "    fingerprints.append(arr)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Create an instance of the one-hot encoder\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "# Convert the fingerprints to one-hot encoding\n",
        "x = enc.fit_transform(fingerprints)\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# calculate pairwise distance between fingerprints\n",
        "pairwise_distance = distance.cdist(fingerprints, fingerprints, 'euclidean')\n",
        "\n",
        "# define threshold for connecting edges\n",
        "threshold = 0.5\n",
        "\n",
        "# create edges where distance is less than the threshold\n",
        "edge_index = []\n",
        "for i in range(len(pairwise_distance)):\n",
        "    for j in range(i+1, len(pairwise_distance)):\n",
        "        if pairwise_distance[i,j] < threshold:\n",
        "            edge_index.append([i, j])\n",
        "\n",
        "# convert to a tensor\n",
        "edge_index = torch.tensor(edge_index).transpose(0,1)\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# define the reconstruction loss\n",
        "reconstruction_loss = nn.MSELoss()\n",
        "# define the KL divergence loss\n",
        "kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "# define the combined loss function\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = reconstruction_loss(recon_x, x)\n",
        "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# prepare the edges\n",
        "n_epochs = 50\n",
        "\n",
        "# train the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "    z, _ = model(x, edge_index)\n",
        "    loss = loss_function(z, x)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "# Create the model, load trained weights and set it to eval mode\n",
        "model.eval()\n",
        "import os\n",
        "\n",
        "path_to_saved_weights = 'path/to/save/weights'\n",
        "# if directory does not exist create it\n",
        "if not os.path.exists(os.path.dirname(path_to_saved_weights)):\n",
        "    os.makedirs(os.path.dirname(path_to_saved_weights))\n",
        "\n",
        "# save model weights\n",
        "torch.save(model.state_dict(), path_to_saved_weights)\n",
        "\n",
        "model.load_state_dict(torch.load(path_to_saved_weights))\n",
        "# create the model\n",
        "model = GF_VAE(in_feats, hidden_size)\n",
        "# load the weights\n",
        "model.load_state_dict(torch.load(path_to_saved_weights))\n",
        "import torch\n",
        "\n",
        "# convert the one-hot encoded fingerprints to a Pytorch tensor\n",
        "input_features = torch.from_numpy(x.toarray()).float()\n",
        "\n",
        "\n",
        "# Prepare the input data\n",
        "x = input_features\n",
        "\n",
        "\n",
        "# get the embeddings\n",
        "_, z = model(x, edge_index)\n",
        "\n",
        "# print the embeddings\n",
        "print(z)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "KbnIaZHhWtRI",
        "outputId": "85f49181-6033-47f0-c0af-af991b02c8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=3e6d329b865d2cab3bd93c38de007c57567f823dea21a789a71391522bb56e9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: psutil, torch_geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch_geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ept-L1LmVy31",
        "outputId": "309f9282-211a-4b8f-94fb-4a6d23134fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGqcR0d6WO6t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "V3-J0JlHK-ic",
        "outputId": "4cd088d2-7617-4055-c8f5-2fd81376895f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-542311a0-60dc-431d-9efe-f7e531df3f3c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-542311a0-60dc-431d-9efe-f7e531df3f3c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (9).csv\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-832534ccd3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msmiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_smiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-832534ccd3ec>\u001b[0m in \u001b[0;36msmiles_to_graph\u001b[0;34m(valid_smiles)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolToImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdmolops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAdjacencyMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetConformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetPositions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Bad Conformer Id"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as gnn\n",
        "from torch_geometric.data import Data\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "df = files.upload()\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"BBBP.csv\")\n",
        "valid_smiles = []\n",
        "for smiles in df[\"smiles\"]:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        valid_smiles.append(smiles)\n",
        "        \n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = gnn.GCNConv(3, 64)\n",
        "        self.conv2 = gnn.GCNConv(64, 128)\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.conv1 = gnn.GCNConv(128, 64)\n",
        "        self.conv2 = gnn.GCNConv(64, 3)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    def forward(self, data):\n",
        "        x = self.encoder(data)\n",
        "        x = self.decoder(x, data.edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def smiles_to_graph(valid_smiles):\n",
        "    mol = Chem.MolFromSmiles(valid_smiles)\n",
        "    img = Draw.MolToImage(mol)\n",
        "    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "    x = mol.GetConformer().GetPositions()\n",
        "    edge_index = torch.nonzero(adj)\n",
        "    return Data(x=torch.tensor(x), edge_index=edge_index)\n",
        "\n",
        "\n",
        "for smiles in valid_smiles:\n",
        "    graph = smiles_to_graph(smiles)\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters())\n",
        "for smiles in valid_smiles:\n",
        "                          graph = smiles_to_graph(smiles)\n",
        "\n",
        "# Pass the graph through the encoder to generate an embedding\n",
        "embedding = autoencoder.encoder(graph)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1kfbGNnUP9eN",
        "outputId": "02ac92ac-8db3-4998-c3cb-4af314c78ded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6fa81784-8908-4c16-833a-c114da527bcc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6fa81784-8908-4c16-833a-c114da527bcc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (10).csv\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ac3e06f7af45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDrugDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;31m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;31m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   6334\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cast_data_without_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_data_without_dtype\u001b[0;34m(subarr)\u001b[0m\n\u001b[1;32m   6409\u001b[0m     \"\"\"\n\u001b[1;32m   6410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6411\u001b[0;31m     result = lib.maybe_convert_objects(\n\u001b[0m\u001b[1;32m   6412\u001b[0m         \u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6413\u001b[0m         \u001b[0mconvert_datetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 3)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "Dataset = files.upload()\n",
        "import pandas as pd\n",
        "Dataset=pd.read_csv(\"BBBP.csv\")\n",
        "valid_smiles = []\n",
        "for smiles in df[\"smiles\"]:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        valid_smiles.append(smiles)\n",
        "        \n",
        "\n",
        "class DrugDataset(Dataset):\n",
        "    def __init__(self, smiles):\n",
        "        self.smiles = smiles\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mol = Chem.MolFromSmiles(self.smiles[idx])\n",
        "        img = Draw.MolToImage(mol)\n",
        "        return img\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 64 * 64, 100)\n",
        "        self.fc2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # Initialize the encoder\n",
        "encoder = Encoder()\n",
        "\n",
        "# Initialize the dataset\n",
        "dataset = DrugDataset(valid_smiles)\n",
        "\n",
        "# Iterate through the dataset to obtain embeddings\n",
        "embeddings = []\n",
        "for i in range(len(dataset)):\n",
        "    img = dataset[i]\n",
        "    img = img.reshape(1, 3, img.shape[0], img.shape[1])  # Reshape the image to fit the input of the encoder\n",
        "    img = img.float() / 255  # Normalize the pixel values\n",
        "    embedding = encoder.fc2(encoder(img)).detach().numpy()  # Obtain the embedding for the current sample\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "# The list `embeddings` now contains the embeddings for each sample in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGm4t1e9GQ9F",
        "outputId": "9045050e-4dca-4e74-80b9-e458412fa8c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "f8b7ZD7PHLvf",
        "outputId": "a1058e88-215d-4136-cfde-250e7026424e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=bd9ffce4c64ab5fbc051fd3dd13b213c8f016ec86ff19aebf05f87d53c5cc8e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: psutil, torch_geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch_geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyYyBsJEyJNq",
        "outputId": "f28c4e28-d1d3-44c9-db99-40be86149509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (from deepchem) (2022.9.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "wp1Y5brocRBE",
        "outputId": "5c10e7b1-8d73-4883-dde4-8db4e8d97bb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3cffc935-4f44-420e-ab45-8e60b0966087\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3cffc935-4f44-420e-ab45-8e60b0966087\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving BBBP.csv to BBBP (12).csv\n",
            "Invalid SMILES:O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n",
            "Invalid SMILES:c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
            "Invalid SMILES:Cc1nc(sc1)\\[NH]=C(\\N)N\n",
            "Invalid SMILES:s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n",
            "Invalid SMILES:c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n",
            "Invalid SMILES:n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n",
            "Invalid SMILES:n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n",
            "Invalid SMILES:n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n",
            "Invalid SMILES:n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n",
            "Invalid SMILES:s1cc(nc1\\[NH]=C(\\N)N)C\n",
            "Invalid SMILES:c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-433bac042a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Build the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0min_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/view.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_n_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mColumn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \"\"\"\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'x'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import dgl\n",
        "import rdkit.Chem as Chem\n",
        "import torch.nn as nn\n",
        "from dgl.nn import SAGEConv\n",
        "from google.colab import files\n",
        "df=files.upload()\n",
        "# Load the SMILES dataset\n",
        "df = pd.read_csv(\"BBBP.csv\")\n",
        "smiles_list = df[\"smiles\"].tolist()\n",
        "\n",
        "# Convert the SMILES strings into DGL graphs\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "from dgl import DGLGraph\n",
        "\n",
        "graphs = []\n",
        "for smiles in smiles_list:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        adj_matrix = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "        src, dst = np.where(adj_matrix)\n",
        "        graph = dgl.DGLGraph((src, dst))\n",
        "        graphs.append(graph)\n",
        "    else:\n",
        "        print(\"Invalid SMILES:{}\".format(smiles))\n",
        "\n",
        "# Define the Graph Auto-Encoder model\n",
        "class GAE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size, k):\n",
        "        super(GAE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, hidden_size, k)\n",
        "        self.conv2 = SAGEConv(hidden_size, hidden_size, k)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, in_feats)\n",
        "\n",
        "    def forward(self, g):\n",
        "        g.ndata['h'] = g.ndata['x']\n",
        "        g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
        "        g.ndata['h'] = self.conv1(g, g.ndata['h'])\n",
        "        g.ndata['h'] = self.fc1(g.ndata['h'])\n",
        "        embeddings = g.ndata['h']\n",
        "        return embeddings\n",
        "        graphs = [g.to(torch.device('cuda:0')) for g in graphs]\n",
        "    \n",
        "\n",
        "# Build the model\n",
        "for i, graph in enumerate(graphs):\n",
        "    x = torch.randn((graph.number_of_nodes(), in_feats))\n",
        "    graph.ndata['x'] = x\n",
        "    # pass graph through the model\n",
        "    embeddings = model(graph)\n",
        "    # calculate the loss\n",
        "    target = torch.Tensor(embeddings.size())\n",
        "    loss = criterion(embeddings, target)\n",
        "    # backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "in_feats = graph.ndata[\"x\"].size()[1]\n",
        "hidden_size = 256\n",
        "\n",
        "# define the loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "IjiaKOdkuU88",
        "outputId": "9444bd6b-63ab-474d-efe4-72ed9256092e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2527784f2e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Need to ensure that the backend framework is imported before load dgl libs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# otherwise weird cuda problem happens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36mload_backend\u001b[0;34m(mod_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using backend: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mthismod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/backend/pytorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0m_deprecate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTargetCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/ndarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObjectBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_init_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDGLContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDGLType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/_ffi/object.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobject_generic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObjectGeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_FFI_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/_ffi/object_generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Object base class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/_ffi/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# library instance of nnvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0m_LIB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_LIB_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# The FFI mode of DGL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/_ffi/base.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"Load libary by searching possible path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# DMatrix functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: libcudart.so.10.0: cannot open shared object file: No such file or directory"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import dgl\n",
        "import rdkit.Chem as Chem\n",
        "import torch.nn as nn\n",
        "from dgl.nn import SAGEConv\n",
        "from google.colab import files\n",
        "df=files.upload()\n",
        "# Load the SMILES dataset\n",
        "df = pd.read_csv(\"BBBP.csv\")\n",
        "smiles_list = df[\"smiles\"].tolist()\n",
        "\n",
        "# Convert the SMILES strings into DGL graphs\n",
        "graphs = []\n",
        "for smiles in smiles_list:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        adj_matrix = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
        "        src, dst = np.where(adj_matrix)\n",
        "        graph = dgl.DGLGraph((src, dst))\n",
        "        graphs.append(graph)\n",
        "    else:\n",
        "        print(\"Invalid SMILES:{}\".format(smiles))\n",
        "        \n",
        "#Convert the graphs to PyTorch tensors\n",
        "graphs = [g.to(torch.device('cuda:0')) for g in graphs]\n",
        "\n",
        "# Define the Graph Auto-Encoder model\n",
        "class GAE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size, k):\n",
        "        super(GAE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, hidden_size, k)\n",
        "        self.conv2 = SAGEConv(hidden_size, hidden_size, k)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, in_feats)\n",
        "embeddings = []\n",
        "for graph in graphs:\n",
        "    graph.ndata['x'] = torch.randn((graph.number_of_nodes(), in_feats)).to(torch.device('cuda:0'))\n",
        "    emb = model(graph)\n",
        "    emb = emb.detach().cpu().numpy()\n",
        "    embeddings.append(emb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLEew8ytwDr4",
        "outputId": "d254ee47-9994-4571-9d86-4a5fc6afbddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.8.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POZnLOjTv6MO"
      },
      "outputs": [],
      "source": [
        "!pip freeze | grep cudatoolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOrqhetvCyI",
        "outputId": "df8eb56d-842f-4844-fac0-a743e91f6479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl-cu100 in /usr/local/lib/python3.8/dist-packages (0.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu100) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu100) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu100) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl-cu100) (2.8.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu100) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu100) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu100) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl-cu100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E8joZkdvLa_",
        "outputId": "e5b3aacb-9faf-4e23-c4df-bd92cc2626c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit==11.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cudatoolkit==11.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install cudatoolkit==11.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzRpwGi6vQeB",
        "outputId": "0f0d4c92-e9f5-4129-f3ae-122e83b5d791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit==11.1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cudatoolkit==11.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install cudatoolkit==11.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylguTPCZWm_G",
        "outputId": "1c39c046-3c2a-4845-b4f6-832545e8ad14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 KB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.0.2)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2022.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: rdkit, deepchem\n",
            "Successfully installed deepchem-2.7.1 rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "HmR_1R0wtEjY",
        "outputId": "cad58b88-f9d6-4311-b560-ce9345482ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=41ea3b1b0c441b1f7a4a0d77f8dae5fa0bd0ec6b724076d7764c8138f04d8c09\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: psutil, torch_geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch_geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qx-L1Besg3u",
        "outputId": "986c709d-a67f-490e-e84a-b44a62b853b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwe4M1cwbdp1",
        "outputId": "8394c6d1-045c-4b22-a855-3975a9701397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 361, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 348, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 222, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 269, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "  File \"/usr/lib/python3.8/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 205, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1434, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.8/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1187, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 110, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 676, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 626, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 103, in print_exception\n",
            "    for line in TracebackException(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 508, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 366, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 288, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 95, in updatecache\n",
            "    stat = os.stat(fullname)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-sparse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZsihKZMd4Xs",
        "outputId": "4833a350-9c13-400d-f740-b24c599eb7ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse==0.4.3\n",
            "  Downloading torch_sparse-0.4.3.tar.gz (11 kB)\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-51rjwnu_/torch_sparse.egg-info/SOURCES.txt'\n",
            "  No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse==0.4.3) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse==0.4.3) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Running command python setup.py bdist_wheel\n",
            "  No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  running bdist_wheel\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  running build\n",
            "  running build_py\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  creating build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spspmm_spmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_coalesce.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_convert.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spspmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_eye.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_transpose.py -> build/lib.linux-x86_64-3.8/test\n",
            "  creating build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  copying torch_sparse/utils/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  copying torch_sparse/utils/unique.py -> build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_sparse.spspmm_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c cpu/spspmm.cpp -o build/temp.linux-x86_64-3.8/cpu/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spspmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/cpu/spspmm.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/spspmm_cpu.cpython-38-x86_64-linux-gnu.so\n",
            "  building 'torch_sparse.spspmm_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c cuda/spspmm.cpp -o build/temp.linux-x86_64-3.8/cuda/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp: In function ‘std::tuple<at::Tensor, at::Tensor> spspmm(at::Tensor, at::Tensor, at::Tensor, at::Tensor, size_t, size_t, size_t)’:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:15:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:16:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:17:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:18:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp: In function ‘at::Tensor spspmm_bw(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, size_t, size_t)’:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:25:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(index);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:27:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:28:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:29:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "    warnings.warn(\"Can't initialize NVML\")\n",
            "  Traceback (most recent call last):\n",
            "    File \"<string>\", line 2, in <module>\n",
            "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "    File \"/tmp/pip-install-_m58hhmp/torch-sparse_168f216c1ff04855a458d6f19a45bdcc/setup.py\", line 42, in <module>\n",
            "      setup(\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/setuptools/__init__.py\", line 153, in setup\n",
            "      return distutils.core.setup(**attrs)\n",
            "    File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\n",
            "      dist.run_commands()\n",
            "    File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\n",
            "      self.run_command(cmd)\n",
            "    File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
            "      cmd_obj.run()\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/wheel/bdist_wheel.py\", line 325, in run\n",
            "      self.run_command(\"build\")\n",
            "    File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
            "      self.distribution.run_command(command)\n",
            "    File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
            "      cmd_obj.run()\n",
            "    File \"/usr/lib/python3.8/distutils/command/build.py\", line 135, in run\n",
            "      self.run_command(cmd_name)\n",
            "    File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
            "      self.distribution.run_command(command)\n",
            "    File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
            "      cmd_obj.run()\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 79, in run\n",
            "      _build_ext.run(self)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
            "      _build_ext.build_ext.run(self)\n",
            "    File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\n",
            "      self.build_extensions()\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\n",
            "      build_ext.build_extensions(self)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\n",
            "      _build_ext.build_ext.build_extensions(self)\n",
            "    File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n",
            "      self._build_extensions_serial()\n",
            "    File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n",
            "      self.build_extension(ext)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 202, in build_extension\n",
            "      _build_ext.build_extension(self, ext)\n",
            "    File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 528, in build_extension\n",
            "      objects = self.compiler.compile(sources,\n",
            "    File \"/usr/lib/python3.8/distutils/ccompiler.py\", line 574, in compile\n",
            "      self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 581, in unix_wrap_single_compile\n",
            "      cflags = unix_cuda_flags(cflags)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 548, in unix_cuda_flags\n",
            "      cflags + _get_cuda_arch_flags(cflags))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 1780, in _get_cuda_arch_flags\n",
            "      arch_list[-1] += '+PTX'\n",
            "  IndexError: list index out of range\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/usr/bin/python3 -u -c '\u001b[0m\n",
            "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
            "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
            "\u001b[34m  #\u001b[0m\n",
            "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
            "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
            "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
            "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
            "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
            "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
            "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
            "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  try:\u001b[0m\n",
            "\u001b[34m      import setuptools\u001b[0m\n",
            "\u001b[34m  except ImportError as error:\u001b[0m\n",
            "\u001b[34m      print(\u001b[0m\n",
            "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
            "\u001b[34m          \"the build environment.\",\u001b[0m\n",
            "\u001b[34m          file=sys.stderr,\u001b[0m\n",
            "\u001b[34m      )\u001b[0m\n",
            "\u001b[34m      sys.exit(1)\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  __file__ = %r\u001b[0m\n",
            "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
            "\u001b[34m      filename = __file__\u001b[0m\n",
            "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
            "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
            "\u001b[34m  else:\u001b[0m\n",
            "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
            "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
            "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/tmp/pip-install-_m58hhmp/torch-sparse_168f216c1ff04855a458d6f19a45bdcc/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' bdist_wheel -d /tmp/pip-wheel-e8xxow0f\u001b[0m\n",
            "  \u001b[1;35mcwd\u001b[0m: /tmp/pip-install-_m58hhmp/torch-sparse_168f216c1ff04855a458d6f19a45bdcc/\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
            "  Running command python setup.py clean\n",
            "  No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  running clean\n",
            "  removing 'build/temp.linux-x86_64-3.8' (and everything under it)\n",
            "  removing 'build/lib.linux-x86_64-3.8' (and everything under it)\n",
            "  'build/bdist.linux-x86_64' does not exist -- can't clean it\n",
            "  'build/scripts-3.8' does not exist -- can't clean it\n",
            "  removing 'build'\n",
            "Failed to build torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "  Running command Running setup.py install for torch-sparse\n",
            "  No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  running install\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  creating build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spspmm_spmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_coalesce.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_convert.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spspmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_eye.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_spmm.py -> build/lib.linux-x86_64-3.8/test\n",
            "  copying test/test_transpose.py -> build/lib.linux-x86_64-3.8/test\n",
            "  creating build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  copying torch_sparse/utils/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  copying torch_sparse/utils/unique.py -> build/lib.linux-x86_64-3.8/torch_sparse/utils\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_sparse.spspmm_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c cpu/spspmm.cpp -o build/temp.linux-x86_64-3.8/cpu/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spspmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/cpu/spspmm.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/spspmm_cpu.cpython-38-x86_64-linux-gnu.so\n",
            "  building 'torch_sparse.spspmm_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c cuda/spspmm.cpp -o build/temp.linux-x86_64-3.8/cuda/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp: In function ‘std::tuple<at::Tensor, at::Tensor> spspmm(at::Tensor, at::Tensor, at::Tensor, at::Tensor, size_t, size_t, size_t)’:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:15:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:16:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:17:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:18:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp: In function ‘at::Tensor spspmm_bw(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, size_t, size_t)’:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:25:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(index);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:27:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueA);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:28:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(indexB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/c10/core/Device.h:5:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  cuda/spspmm.cpp:3:41: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                                           ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:264:39: note: in definition of macro ‘C10_EXPAND_MSVC_WORKAROUND’\n",
            "   #define C10_EXPAND_MSVC_WORKAROUND(x) x\n",
            "                                         ^\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:284:34: note: in expansion of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY_OR_CONST(e) C10_UNLIKELY(e)\n",
            "                                    ^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:336:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                          \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/c10/util/Exception.h:631:32: note: in expansion of macro ‘TORCH_INTERNAL_ASSERT’\n",
            "       C10_EXPAND_MSVC_WORKAROUND(TORCH_INTERNAL_ASSERT(cond, __VA_ARGS__)); \\\n",
            "                                  ^~~~~~~~~~~~~~~~~~~~~\n",
            "  cuda/spspmm.cpp:3:23: note: in expansion of macro ‘AT_ASSERTM’\n",
            "   #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be CUDA tensor\")\n",
            "                         ^~~~~~~~~~\n",
            "  cuda/spspmm.cpp:29:3: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     CHECK_CUDA(valueB);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from cuda/spspmm.cpp:1:\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:216:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  Running setup.py install for torch-sparse ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch-sparse\n",
        "!pip uninstall torch-sparse\n",
        "!pip install --verbose torch-sparse==0.4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycaH4rFweeh7",
        "outputId": "195220cc-4d10-4119-9bf1-b74bcbe8a559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-sparse, torch-scatter, torch-cluster\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 361, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 348, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 222, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 269, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 205, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1434, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.8/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1187, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 110, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 676, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 626, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 103, in print_exception\n",
            "    for line in TracebackException(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 508, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 366, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 288, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 137, in updatecache\n",
            "    lines = fp.readlines()\n",
            "  File \"/usr/lib/python3.8/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric \\\n",
        "  torch-sparse \\\n",
        "  torch-scatter \\\n",
        "  torch-cluster \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swp8dbzZfDbe",
        "outputId": "c14baa11-7178-4e2a-fd0e-e2737cb8e84e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.0+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.16+pt113cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "jBUsdhaSaCj6",
        "outputId": "9a4fd54f-e38d-43e8-b36f-8299560bdb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=7e0ce44f9762b8700f83511e1b106fbf75b97a91795bc94c544e17917463c439\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "3e71e0c1465a0fac3e495801f7a6fb448cef63610b0348ba82fb26a800360512"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
