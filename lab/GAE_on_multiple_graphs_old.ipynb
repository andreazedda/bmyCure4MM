{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unitary p_np values:  1567\n",
      "Total number of zero p_np values:  483\n",
      "Total number of p_np values:  2050\n",
      "Percentage of unitary p_np values:  76.44 %\n",
      "Percentage of zero p_np values:  23.56 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This is graph autoencoder.\n",
    "The autoencoder is trained taking as input many graphs.\n",
    "The learned task of the autoencoder is to reconstruct a given molecule. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the data\n",
    "drug_data=pd.read_csv(\"BBBP.csv\")\n",
    "\n",
    "#sum all values equal to 1 in p_np column of drug_data\n",
    "total_unitary_pnp = sum(drug_data.p_np==1)\n",
    "print (\"Total number of unitary p_np values: \", total_unitary_pnp)\n",
    "\n",
    "#sum all values equal to 0 in p_np column of drug_data\n",
    "total_zero_pnp = sum(drug_data.p_np==0)\n",
    "print (\"Total number of zero p_np values: \", total_zero_pnp)\n",
    "\n",
    "# Print the total number of p_np values\n",
    "print (\"Total number of p_np values: \", len(drug_data.p_np))\n",
    "\n",
    "# Calculate the percentage of unitary p_np values\n",
    "print (\"Percentage of unitary p_np values: \", round(total_unitary_pnp*100/len(drug_data.p_np),2), \"%\")\n",
    "\n",
    "#calculate the percentage of zero p_np values\n",
    "print (\"Percentage of zero p_np values: \", round (total_zero_pnp*100/len(drug_data.p_np),2), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (utils.py, line 55)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3442\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\n\u001b[0;31m    from utils import *\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/bmyCure4MM/utils.py:55\u001b[0;36m\u001b[0m\n\u001b[0;31m    img.save(\"./media/\" + name + \".jpg\")\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from utils import *\n",
    "from matplotlib import colors\n",
    "from rdkit.Chem.Draw import MolToImage\n",
    "\n",
    "# check the data frame\n",
    "drug_data.head()\n",
    "\n",
    "#extract smiles from the data frame and check the first 10 smiles\n",
    "smiles = drug_data['smiles']\n",
    "smiles.head()\n",
    "\n",
    "#convert smiles to mols and disable warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "mols\n",
    "print (type(mols[0]))\n",
    "\n",
    "#resizing the drug_data to \n",
    "end_of_array = 20\n",
    "smiles=smiles[:end_of_array]\n",
    "print(smiles)\n",
    "\n",
    "# Create a graph representation of the first molecule\n",
    "for i in range(0, end_of_array):\n",
    "    name = drug_data['name'][i]\n",
    "    img = get_image(mols[i],None , name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First object in the data_list: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "# Load the smiles and create the graph representation\n",
    "smiles = drug_data['smiles'].to_list()\n",
    "# Resize the array\n",
    "smiles = smiles[:end_of_array]\n",
    "\n",
    "# Load the labels we don't want to use them for training the autoencoder\n",
    "labels = drug_data['p_np'].to_list()\n",
    "# Resize the array\n",
    "labels = labels[:end_of_array]\n",
    "\n",
    "\n",
    "# Create a list of PyTorch Geometric Data objects\n",
    "data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(smiles, labels)\n",
    "print (\"First object in the data_list: \" + str(data_list[0].x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "import random\n",
    "random.shuffle(data_list)\n",
    "train = data_list[:int(len(data_list)*0.8)] #train set\n",
    "test = data_list[int(len(data_list)*0.2):] #val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in the training set: 16\n",
      "Number of graphs in the test set: 16\n",
      "Number of nodes in the first graph in the training set: 49\n",
      "DataBatch(x=[430, 79], edge_index=[2, 926], edge_attr=[926, 10], y=[16], batch=[430], ptr=[17])\n",
      "16\n",
      "torch.Size([16, 79])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "print (\"Number of graphs in the training set: \" + str(len(train)))\n",
    "print (\"Number of graphs in the test set: \" + str(len(test)))\n",
    "print (\"Number of nodes in the first graph in the training set: \" + str(train[0].x.shape[0]))\n",
    "loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "# batch = next(iter(loader))\n",
    "# print(batch)\n",
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.num_graphs)\n",
    "    x = scatter(data.x, data.batch, dim=0, reduce='mean')\n",
    "    print(x.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[39m# Define the model encoder\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGCNEncoder\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      5\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_channels, out_channels):\n\u001b[1;32m      6\u001b[0m         \u001b[39msuper\u001b[39m(GCNEncoder, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define the model encoder\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    \n",
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = loader.ba   .num_features\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = loader.x.to(device)\n",
    "train_pos_edge_index = loader.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# class GAE(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(GAE, self).__init__()\n",
    "#         self.conv1 = GCNConv(in_channels, 2*out_channels)\n",
    "#         self.conv2 = GCNConv(2*out_channels, out_channels)\n",
    "#         self.conv3 = GCNConv(out_channels, in_channels)\n",
    "        \n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = torch.relu(x)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = torch.relu(x)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features (used as input): 79\n",
      "out channels: 2\n",
      "<generator object Module.parameters at 0x29250f530>\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU, CrossEntropyLoss\n",
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = data_list[0].x.shape[1] #input to the encoder\n",
    "print(\"num_features (used as input): \" + str(num_features))\n",
    "print(\"out channels: \" + str(out_channels))\n",
    "epochs = 100\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #use CUDA if available\n",
    "model = model.to(device) #create network and send to the device memory\n",
    "print(model.parameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #use Adam optimizer\n",
    "CSE = CrossEntropyLoss() #define loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: Data(x=[3, 79], edge_index=[2, 4], edge_attr=[4, 10], y=[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [GAE] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data))\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m#zero gradients\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m out \u001b[39m=\u001b[39m model(d) \u001b[39m#evaluate data point\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     num_correct += 1\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mout: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out))\n",
      "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bmyCure4MM/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:246\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [GAE] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "from tqdm import tqdm\n",
    "model.train() #set model to training mode\n",
    "for epoch in range(2): #run for epochs of training\n",
    "    sum_loss = 0 #used to compute average loss in an epoch\n",
    "    num_correct = 0\n",
    "    random.shuffle(train) #shuffle the training data each epoch\n",
    "    for d in tqdm(train): #go over each training point\n",
    "        data = d.to(device) #send data to device\n",
    "        print(\"data: \" + str(data))\n",
    "        optimizer.zero_grad() #zero gradients\n",
    "        out = model(d) #evaluate data point\n",
    "        # if torch.argmax(out) == torch.argmax(data.y): #if prediction is correct, increment counter for accuracy calculation\n",
    "        #     num_correct += 1\n",
    "        print(\"out: \" + str(out))\n",
    "        loss = CSE(torch.reshape(out, [1, 3]), torch.reshape(torch.argmax(data.y),[1])) #compute mean squared error loss\n",
    "        sum_loss += float(loss) #add loss value to aggregate loss\n",
    "        loss.backward() #compute gradients\n",
    "        optimizer.step() #apply optimization\n",
    "    print('Epoch: {:03d}, Average loss: {:.5f}, Accuracy: {:.5f}'.format(epoch, sum_loss/len(train), num_correct/len(train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e71e0c1465a0fac3e495801f7a6fb448cef63610b0348ba82fb26a800360512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
